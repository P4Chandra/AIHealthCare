{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pneumonia Detection using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Special thanks to Paul Mooney for Datasets on Chest-Xray images for Pneumonia !!\n",
    "\n",
    "Here is the link to dataset. https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia#chest_xray.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header declarations and detect  CUDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-200577ff0be3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "device='cpu'\n",
    "\n",
    "if train_on_gpu:\n",
    "    print(\"Cuda is available\")\n",
    "    device='cuda'\n",
    "else:\n",
    "    print(\"CPU is available\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load Images from root folder and pre-process them and create DataLoaders\n",
    "\n",
    "Transforms\n",
    "When you load in the data with ImageFolder, you'll need to define some transforms. For example, the images are different sizes but we'll need them to all be the same size for training. You can either resize them with transforms.Resize() or crop with transforms.CenterCrop(), transforms.RandomResizedCrop(), etc. We'll also need to convert the images to PyTorch tensors with transforms.ToTensor()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test data directories\n",
    "data_dir = 'pneumonia_images/'\n",
    "train_dir = os.path.join(data_dir, 'train/')\n",
    "test_dir = os.path.join(data_dir, 'test/')\n",
    "\n",
    "#preprocess and convert to tensor\n",
    "data_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "#load and transform data from given path\n",
    "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
    "test_data =  datasets.ImageFolder(test_dir,transform=data_transform)\n",
    "\n",
    "#create DataLoaders for training set and test set\n",
    "train_loader = torch.utils.data.Dataloader(train_data,batch_size=32,shuffle=True)\n",
    "test_loader  = torch.utils.data.Dataloader(test_data,batch_size=32,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data from test and train loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some sample data\n",
    "\n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy() # convert images to numpy for display\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
    "    ax.set_title(labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A CNN architecture \n",
    "defining a model from scratch. This may not be nearly good enough for detecting infection.But let's just give it a try. \n",
    "The architecture has 5 Convolution layers, each convolution layer uses RELU activation function, followed by maxpool that reduces the width and height of input by a factor of 2. \n",
    "\n",
    "Final layers are 2 fully connected Linear layers with droput of 0.2 and again uses relu activation. \n",
    "\n",
    "We can compute the spatial size of the output volume as a function of the input volume size (W), the kernel/filter size (F), the stride with which they are applied (S), and the amount of zero padding used (P) on the border. The correct formula for calculating how many neurons define the output_W is given by (Wâˆ’F+2P)/S+1.\n",
    "\n",
    "For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 we would get a 5x5 output. With stride 2 we would get a 3x3 output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class XRayNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XRayNet, self).__init__()\n",
    "        # convolutional layer (sees 224x224*1 image tensor)\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        # convolutional layer (sees 112*112*16 image tensor)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        # convolutional layer (sees 56*56*32 image tensor)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        # convolutional layer (sees 28*28*64 image tensor)\n",
    "        self.conv4 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        # convolutional layer (sees 14*14*128 image tensor)\n",
    "        self.conv5 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        # max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # linear layer (7 * 7 * 256)\n",
    "        self.fc1=nn.Linear(7 * 7 * 256,200)\n",
    "        # linear layer (7 * 7 * 256)\n",
    "        self.fc2=nn.Linear(200,2)\n",
    "        #dropout layer\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # add sequence of convolutional and max pooling layers\n",
    "        x= self.pool(F.Relu(self.conv1(x)))\n",
    "        x= self.pool(F.Relu(self.conv2(x)))\n",
    "        x= self.pool(F.Relu(self.conv3(x)))\n",
    "        x= self.pool(F.Relu(self.conv4(x)))\n",
    "        x= self.pool(F.Relu(self.conv5(x)))\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 256 * 7 * 7)\n",
    "        \n",
    "        # first fully connected layer\n",
    "        x= self.dropout(x)\n",
    "        x= F.Relu(self.fc1(x))\n",
    "        # second fully connected layer\n",
    "        x= self.dropout(x)\n",
    "        x= F.Relu(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "# create a complete CNN\n",
    "model = XRayNet()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Loss Function and Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = optim.Adam(model.parameters,lr=0.01)#optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=20\n",
    "\n",
    "for epoch in range(1,num_epochs):\n",
    "    train_loss=0.0\n",
    "    for images,labels in train_loader:\n",
    "        images,labels=images.cuda(),labels.cuda()\n",
    "        # reset to calculate new weights\n",
    "        optimizer.zero_grad()\n",
    "        #forward pass\n",
    "        output=model(images)\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, labels)\n",
    "         # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "    # calculate average losses\n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    print('For Epoch {} \\t training loss is {:.6f}',epoch,train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Trained Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval() # prep model for evaluation\n",
    "\n",
    "for data, target in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.sampler)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n",
    "      \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
