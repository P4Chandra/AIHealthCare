{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fs=125 #sampling rate\n",
    "minfreq=0.66 #40 bpm\n",
    "maxfreq=4 #240\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estim0tes = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "    \n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "        \n",
    "    # Compute pulse rate estimates and estimation confidence.\n",
    "    errors, confidence = estimatePulseRate(ppg, accx, accy, accz)\n",
    "    # Return per-estimate mean absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    #errors, confidence = np.ones(100), np.ones(100)  # Dummy placeholders. Remove\n",
    "    return errors, confidence\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### My implementation ,the code in above section is skeletal code provided by udacity.\n",
    "\n",
    "Below are some of the knowledge links used for reference and adapted sample code from here.\n",
    "\n",
    "https://knowledge.udacity.com/questions/314330\n",
    "\n",
    "https://knowledge.udacity.com/questions/399609\n",
    "\n",
    "https://knowledge.udacity.com/questions/246546\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADlVJREFUeJzt3X+s3Xddx/HnizYdQX5so3eKa0tLKIkdMSzeVA2JDmHSkdgSQewSwlCkf+g0ETCWjCww/ANGDGic0WYa5xLoNojSSM2CExJjGO5OBtLNsmsH7lriLmwhQQKz4e0f9wsezs5tu/P93nt6+Twfyc093+/53O/n89lNnj07595zU1VIktryjFkvQJK0/oy/JDXI+EtSg4y/JDXI+EtSg4y/JDXI+EtSg4y/JDXI+EtSgzbPegGr2bp1a+3cuXPWy5CkDeX+++//WlXNnWvcIPFPsg/4I2ATcGtVvW/s/h3AbcDF3ZjDVXX8bNfcuXMnCwsLQyxPkpqR5CvnM6730z5JNgG3ANcAe4Brk+wZG/Yu4M6quhI4CPxp33klSdMb4jn/vcBiVZ2qqieBo8CBsTEFPLe7/Tzg9ADzSpKmNET8LwceHTle6s6NejfwxiRLwHHgtyddKMmhJAtJFpaXlwdYmiRpkiHinwnnxt8n+lrgr6pqG/Aa4PYkT5m7qo5U1XxVzc/NnfP1CknSlIaI/xKwfeR4G099WuctwJ0AVfUZ4JnA1gHmliRNYYj43wfsTrIryRZWXtA9NjbmP4FXAiT5CVbi7/M6kjQjveNfVWeA64G7gYdY+ameE0luSrK/G/Z24K1JPg98BHhz+SfEJGlmBvk5/+5n9o+Pnbtx5PaDwMuHmEuS1J9v7yBJDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDTL+ktQg4y9JDRok/kn2JTmZZDHJ4VXGvCHJg0lOJPnwEPNKkqazue8FkmwCbgGuBpaA+5Icq6oHR8bsBt4JvLyqnkhyWd95JUnTG+KR/15gsapOVdWTwFHgwNiYtwK3VNUTAFX12ADzSpKmNET8LwceHTle6s6NegnwkiT/nOTeJPsmXSjJoSQLSRaWl5cHWJokaZIh4p8J52rseDOwG7gKuBa4NcnFT/miqiNVNV9V83NzcwMsTZI0yRDxXwK2jxxvA05PGPPxqvrfqnoEOMnKPwaSpBkYIv73AbuT7EqyBTgIHBsb87fAKwCSbGXlaaBTA8wtSZpC7/hX1RngeuBu4CHgzqo6keSmJPu7YXcDX0/yIPAp4Peq6ut955YkTSdV40/PXxjm5+drYWFh1suQpA0lyf1VNX+ucf6GryQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1aJD4J9mX5GSSxSSHzzLu9UkqyfwQ80qSptM7/kk2AbcA1wB7gGuT7Jkw7jnA7wCf7TunJKmfIR757wUWq+pUVT0JHAUOTBj3XuBm4NsDzClJ6mGI+F8OPDpyvNSd+74kVwLbq+rvznahJIeSLCRZWF5eHmBpkqRJhoh/Jpyr79+ZPAP4IPD2c12oqo5U1XxVzc/NzQ2wNEnSJEPEfwnYPnK8DTg9cvwc4KXAp5N8GfgZ4Jgv+krS7AwR//uA3Ul2JdkCHASOfe/OqvpGVW2tqp1VtRO4F9hfVQsDzC1JmkLv+FfVGeB64G7gIeDOqjqR5KYk+/teX5I0vM1DXKSqjgPHx87duMrYq4aYU5I0PX/DV5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUHGX5IaZPwlqUGDxD/JviQnkywmOTzh/rcleTDJF5Lck+SFQ8wrSZpO7/gn2QTcAlwD7AGuTbJnbNjngPmq+kngo8DNfeeVJE1viEf+e4HFqjpVVU8CR4EDowOq6lNV9a3u8F5g2wDzSpKmNET8LwceHTle6s6t5i3A3w8wryRpSpsHuEYmnKuJA5M3AvPAz69y/yHgEMCOHTsGWJokaZIhHvkvAdtHjrcBp8cHJXkVcAOwv6q+M+lCVXWkquaran5ubm6ApUmSJhki/vcBu5PsSrIFOAgcGx2Q5Ergz1kJ/2MDzClJ6qF3/KvqDHA9cDfwEHBnVZ1IclOS/d2wDwDPBu5K8kCSY6tcTpK0DoZ4zp+qOg4cHzt348jtVw0xjyRpGP6GryQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1yPhLUoOMvyQ1aJD4J9mX5GSSxSSHJ9x/UZI7uvs/m2TnEPNKkqbTO/5JNgG3ANcAe4Brk+wZG/YW4ImqejHwQeD9feeVJE1viEf+e4HFqjpVVU8CR4EDY2MOALd1tz8KvDJJBphbkjSFIeJ/OfDoyPFSd27imKo6A3wDeP4Ac0uSpjBE/Cc9gq8pxpDkUJKFJAvLy8sDLE2SNMkQ8V8Cto8cbwNOrzYmyWbgecDj4xeqqiNVNV9V83NzcwMsTZI0yRDxvw/YnWRXki3AQeDY2JhjwHXd7dcD/1hVT3nkL0laH5v7XqCqziS5Hrgb2AT8ZVWdSHITsFBVx4C/AG5PssjKI/6DfeeVJE2vd/wBquo4cHzs3I0jt78N/MoQc0mS+vM3fCWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQcZfkhpk/CWpQb3in+TSJJ9M8nD3+ZIJY16W5DNJTiT5QpJf7TOnJKm/vo/8DwP3VNVu4J7ueNy3gDdV1RXAPuBDSS7uOa8kqYe+8T8A3Nbdvg147fiAqvpSVT3c3T4NPAbM9ZxXktRD3/j/aFV9FaD7fNnZBifZC2wB/qPnvJKkHjafa0CSfwB+bMJdNzydiZK8ALgduK6qvrvKmEPAIYAdO3Y8nctLkp6Gc8a/ql612n1J/jvJC6rqq13cH1tl3HOBTwDvqqp7zzLXEeAIwPz8fJ1rbZKk6fR92ucYcF13+zrg4+MDkmwB/gb466q6q+d8kqQB9I3/+4CrkzwMXN0dk2Q+ya3dmDcAPwe8OckD3cfLes4rSeohVRfmsytJloGvzHodU9gKfG3Wi1hn7rkN7nljeGFVnfMnKi/Y+G9USRaqan7W61hP7rkN7vmHi2/vIEkNMv6S1CDjP7wjs17ADLjnNrjnHyI+5y9JDfKRvyQ1yPhP4Xzeyrobd1035uEk1024/1iSL679ivvrs+ckz0ryiST/3r219/vWd/XnL8m+JCeTLCZ5yrvUJrkoyR3d/Z9NsnPkvnd2508mefV6rruPafec5Ook9yf5t+7zL6z32qfV5/vc3b8jyTeTvGO91jy4qvLjaX4ANwOHu9uHgfdPGHMpcKr7fEl3+5KR+38Z+DDwxVnvZ633DDwLeEU3ZgvwT8A1s97ThPVvYuVNB1/UrfPzwJ6xMb8J/Fl3+yBwR3d7Tzf+ImBXd51Ns97TGu/5SuDHu9svBf5r1vtZ6z2P3P8x4C7gHbPez7QfPvKfzjnfyhp4NfDJqnq8qp4APsnK3zMgybOBtwF/sA5rHcrUe66qb1XVpwCq6kngX4Ft67Dmp2svsFhVp7p1HmVl36NG/zt8FHhlknTnj1bVd6rqEWCxu96Fbuo9V9XnauVt2gFOAM9MctG6rLqfPt9nkryWlQc2J9ZpvWvC+E/nfN7K+nLg0ZHjpe4cwHuBP2TlD91sFH33DED3h3x+iZU//nOhOef6R8dU1RngG8Dzz/NrL0R99jzqdcDnquo7a7TOIU295yQ/Avw+8J51WOeaOue7erZqgLeyzoRz1b2v0Yur6nfHn0ectbXa88j1NwMfAf64qk49/RWuubOu/xxjzudrL0R99rxyZ3IF8H7gFwdc11rqs+f3AB+sqm92/yOwYRn/VVT/t7JeAq4aOd4GfBr4WeCnknyZlf/+lyX5dFVdxYyt4Z6/5wjwcFV9aIDlroUlYPvI8Tbg9Cpjlrp/zJ4HPH6eX3sh6rNnkmxj5V1731RVG+WPNPXZ808Dr09yM3Ax8N0k366qP1n7ZQ9s1i86bMQP4AP84IufN08YcynwCCsveF7S3b50bMxONs4Lvr32zMrrGx8DnjHrvZxlj5tZeS53F///QuAVY2N+ix98IfDO7vYV/OALvqfYGC/49tnzxd341816H+u157Ex72YDv+A78wVsxA9Wnu+8B3i4+/y9wM0Dt46M+3VWXvhbBH5twnU2Uvyn3jMrj6wKeAh4oPv4jVnvaZV9vgb4Eis/DXJDd+4mYH93+5ms/JTHIvAvwItGvvaG7utOcgH+NNPQewbeBfzPyPf0AeCyWe9nrb/PI9fY0PH3N3wlqUH+tI8kNcj4S1KDjL8kNcj4S1KDjL8kNcj4S1KDjL8kNcj4S1KD/g88ZsMWTVSGYAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa049a42470>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_spectogram(sig):\n",
    "    \"\"\"\n",
    "    Gets spectrogram and frequencies from given signal. \n",
    "    Calculate the magnitude of the acceleration.\n",
    "    Arguments: \n",
    "        sig: required sensor signal (e.g. ppg or acc)\n",
    "    Returns:\n",
    "        spec: ndarray\n",
    "        freqs: ndarray\n",
    "    adapted from https://knowledge.udacity.com/questions/399609\n",
    "    refered for understanding https://knowledge.udacity.com/questions/246546\n",
    "    refered to https://vibrationresearch.com/blog/what-is-a-spectrogram/\n",
    "    \"\"\"\n",
    "    spec, freqs, t=mlab.specgram(sig,NFFT=fs*8,Fs=fs,noverlap=6*fs, pad_to=10*fs)\n",
    "    spec=spec[(freqs >= minfreq) & (freqs <= maxfreq)]\n",
    "    freqs=freqs[(freqs >= minfreq) & (freqs <= maxfreq)]\n",
    "    \n",
    "    return spec, freqs\n",
    "\n",
    "def BandpassFilter(sig): \n",
    "    \"\"\"\n",
    "    BandpassFilter function  allows certain frequency range only.\n",
    "    Refer to ReadMe.md file for passband range.\n",
    "    the Readme file assumes pulse rate will be restricted between 40BPM (beats per minute) and 240BPM\n",
    "    Banpass Filter code has been adapted from Lowpassfilter in Lesson 3 \n",
    "    Returns:\n",
    "        Filtered signal\n",
    "    \"\"\"\n",
    "    pass_band=(minfreq,maxfreq) \n",
    "    b, a = scipy.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "    return scipy.signal.filtfilt(b, a, sig)\n",
    "\n",
    "def calcSNR(sig, est_freq):\n",
    "    \"\"\"\n",
    "    Calculate Signal to noise ratio to determine how clean the signal is \n",
    "    Refered to Lesson 3 Exercise 3 Solution\n",
    "    SNR was recommended to be used in https://knowledge.udacity.com/questions/399609\n",
    "    \"\"\"\n",
    "    n = len(sig)*2\n",
    "    #frequency of first harmonic\n",
    "    harmonic_f = est_freq * 2\n",
    "    \n",
    "    # do Fourier Transform\n",
    "    fft_mag = np.abs(np.fft.rfft(sig, n))\n",
    "    freqs = np.fft.rfftfreq(n, 1/fs)\n",
    "    \n",
    "    #Find the frequencies close to heart rate and first harmonic of the heart rate\n",
    "    window_f = 5/60\n",
    "    fundamental_frequency_window = (freqs > est_freq - window_f) & (freqs < est_freq + window_f)\n",
    "    harmonic_frequency_window = (freqs > harmonic_f - window_f) & (freqs < harmonic_f + window_f)\n",
    "    \n",
    "    #Calculate signal and noise power\n",
    "    sig = np.sum(fft_mag[(fundamental_frequency_window) | (harmonic_frequency_window)])\n",
    "    noise = np.sum(fft_mag[~ ((fundamental_frequency_window) | (harmonic_frequency_window))])\n",
    "    snr = sig / noise\n",
    "    \n",
    "    return snr\n",
    "\n",
    "def Featurize(ppg,accx, accy, accz,fs=fs):\n",
    "     \"\"\"Featurization of the accelerometer and ppg signal.\n",
    "        Adapted from Lesson 4 .\n",
    "  Args:\n",
    "      accx: (np.array) x-channel of the accelerometer.\n",
    "      accy: (np.array) y-channel of the accelerometer.\n",
    "      accz: (np.array) z-channel of the accelerometer.\n",
    "      fs: (number) the sampling rate of the accelerometer\n",
    "      ppg:  (np.array) ppg signal\n",
    "\n",
    "  Returns:\n",
    "       n-tuple of accelerometer and ppg features\n",
    "    \"\"\"\n",
    "    # Use Bandpass Filter to take out signals below 40 bpm and above 240 bpm\n",
    "    ppg=BandpassFilter(ppg)\n",
    "    accx=BandpassFilter(accx)\n",
    "    accy=BandpassFilter(accy)\n",
    "    accz=BandpassFilter(accz)\n",
    "    \n",
    "    #Get spectrogram frequencies\n",
    "    spec_ppg, freqs_ppg = get_spectogram(ppg)\n",
    "    spec_accx, freqs_accx = get_spectogram(accx)\n",
    "    spec_accy, freqs_accy = get_spectogram(accy)\n",
    "    spec_accz, freqs_accz = get_spectogram(accz)\n",
    "      \n",
    "    #Get frequency and time\n",
    "    freqs = freqs_ppg.shape[0]\n",
    "    t_steps = spec_ppg.shape[1]\n",
    "    \n",
    "    # Get indices for largest signal peaks\n",
    "    ppg_ind = (-spec_ppg).argsort(axis=0)\n",
    "    accx_ind = (-spec_accx).argsort(axis=0)\n",
    "    accy_ind = (-spec_accy).argsort(axis=0)\n",
    "    accz_ind = (-spec_accz).argsort(axis=0)\n",
    "    \n",
    "    return (freqs,t_steps,spec_ppg, freqs_ppg,\n",
    "            ppg_ind,accx_ind,accy_ind,accz_ind)\n",
    "           \n",
    "def estimatePulseRate(ref_f1,ppg,accx, accy, accz,fs=fs): #refer to Lesson 4\n",
    "         \"\"\"Estimates the Pulse Rate of the accelerometer and ppg signal.\n",
    "        Adapted from Lesson 4 .\n",
    "        adapted from https://knowledge.udacity.com/questions/399609\n",
    "        refered for understanding https://knowledge.udacity.com/questions/246546\n",
    "  Args:\n",
    "      accx: (np.array) x-channel of the accelerometer.\n",
    "      accy: (np.array) y-channel of the accelerometer.\n",
    "      accz: (np.array) z-channel of the accelerometer.\n",
    "      fs: (number) the sampling rate of the accelerometer\n",
    "      ppg:  (np.array) ppg signal\n",
    "\n",
    "    Returns:\n",
    "       \n",
    "    \"\"\"\n",
    "    # get Ground Truth \n",
    "     # Load Reference\n",
    "    groundtruth = scipy.io.loadmat(ref_fl)[\"BPM0\"].reshape(-1)\n",
    "    \n",
    "    #Extract strongest frequencies in ppg and accelerometer signals \n",
    "    (freqs,t_steps,spec_ppg, freqs_ppg,\n",
    "     ppg_ind,accx_ind,accy_ind,accz_ind) = Featurize(ppg,accx, accy, accz)\n",
    "    \n",
    "    # Estimate Pulse Rates adapted from https://knowledge.udacity.com/questions/399609\n",
    "    #\n",
    "    estimated_freq=[]\n",
    "    for t in range(t_steps):\n",
    "        for freq in range(freqs):\n",
    "            i=0\n",
    "            if freq == 2:# if just peaks at 2 frequencies just pick ppg\n",
    "                estimated_freq.append(freqs_ppg[ppg_ind[freq][t]])\n",
    "                break\n",
    "            # try to remove accelerometer peaks to identify only ppg\n",
    "            # we are just doing our best to remove peaks caused due to ARM movements\n",
    "            elif np.all([(freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accx_ind[i][t]]), \n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accy_ind[i][t]]), \n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accz_ind[i][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accx_ind[i+1][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accy_ind[i+1][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accz_ind[i+1][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accx_ind[i+2][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accy_ind[i+2][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accz_ind[i+2][t]])]):\n",
    "                estimated_freq.append(freqs_ppg[ppg_ind[freq][t]])\n",
    "                break\n",
    "    # use SNR from Lesson 3 to determine \"purity\" of the ppg signal this is what our confidence is\n",
    "    confidence = []\n",
    "    for i in range(len(estimated_freq)):\n",
    "        snr = calcSNR(ppg, estimated_freq[i])\n",
    "        confidence.append(snr)\n",
    "    \n",
    "    predictor = np.array(estimated_freq) * 60\n",
    "    \n",
    "    #Get Error and Confidence in array\n",
    "    error_arr = np.abs(groundtruth - predictor)\n",
    "    conf_arr = np.array(confidence)\n",
    "    \n",
    "    return error_arr, conf_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** - Include details so someone unfamiliar with your project will know how to run your code and use your algorithm. \n",
    "> - **Data Description** - Describe the dataset that was used to train and test the algorithm. Include its short-comings and what data would be required to build a more complete dataset.\n",
    "> - **Algorithhm Description** will include the following:\n",
    ">   - how the algorithm works\n",
    ">   - the specific aspects of the physiology that it takes advantage of\n",
    ">   - a describtion of the algorithm outputs\n",
    ">   - caveats on algorithm outputs \n",
    ">   - common failure modes\n",
    "> - **Algorithm Performance** - Detail how performance was computed (eg. using cross-validation or train-test split) and what metrics were optimized for. Include error metrics that would be relevant to users of your algorithm. Caveat your performance numbers by acknowledging how generalizable they may or may not be on different datasets.\n",
    "\n",
    "Your write-up goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code Description\n",
    "\n",
    "The code includes starter code to read from the Troika dataset a test set of data as well as reference data. The function to trigger the execution of the algorithm and evaluate it's effectiveness is: Evaluate().\n",
    "\n",
    "Evaluate() uses the LoadTroikaDataset() to retrieve the data and reference filenames of the data to be processed. It then iterates across the data and reference files calling RunPulseRateAlgorithm for each set and aggregating errors and confidences for each set of files. Evaluate then concludes calling AggregateErrorMetrics to evaluate the error and confidence data collected to determine the BPM error rate over the 90% confidence estimates.\n",
    "\n",
    "RunPulseRateAlgorithm() is the heart of the code for evaluating the BPN in 8 second windows that slide 2 seconds each evaluate. A description of the algorithm itself is below in the Algorithm Description section. What is important to note from a code perspective is that RunPulseRateAlgorithm() uses loadTroikaRefFile() to load the reference BPM data recorded every 2 seconds across an 8 second window. RunPulseRateAlgorithm() then takes the data file a breaks it into 8 second windows where it calls featurize() in order to determine the features for evaluation of the algorithm. Each 8 second window will result in a BPM estimate that is compared against the reference data to determine the error. The confidence is the percentage of energy in the frequency used to evaluate the BPM divided by the whole frequency spectrum as a way of estimating confidence that the BPM is the highest energy signal in the data.\n",
    "\n",
    "Once RunPuleRateAlgorithm() evalautes all the 8 second windows it returns error and confidence arrays to Evaluate() when the aggregates the results and loads new file to RunPulseRateAlgorithm() until all files are processed.\n",
    "\n",
    "##### Data Description\n",
    "\n",
    "The algorithm is designed to work on the Troika data set referenced above and noted here as well. The troika dataset includes two data files for each subject, the data file and a reference file. The data file contains 4 arrays of sensor data: one PPG sensor recording and 3 accelermometers (x, y, z axis). The sensors are recording at 8Hz or 125ms time frames. These are extracted in each file. The reference data file contains BPM recordings for 8 second windows recorded every 2 second. Each pair of files represents one test subject starting from rest and starting to run at 15km/hr. This shows BPM starting at resting rate and raising to a high activity rate.\n",
    "\n",
    "There are a few limitations with the data that make it difficult to generalize. First, with only 12 test subjects and no demongraphics data it is unclear if this would generalize to different genders and different ages of individuals. We do know through other medical research that BPM varies siginficantly in individuals based on gender/age so it could be that this test set limits the applicability of any designed algorithm. Additionally the algorithm is only testing an increase in activity and BPM prediction. The data does not have data for returning base to a resting heart rate and the algorithm designed below may not perform well as activity decreases.\n",
    "\n",
    "Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "##### Algorithm Description\n",
    "\n",
    "The algorithm is designed to be execuited within the RunPulseRateAlgorithm() method. Within this method the data is broken down into 8 second windows for processing with the algorithm. The algorithm then uses the featurize() method to determine the important data points for evaluate.\n",
    "\n",
    "Within featurize several processing steps occur. First a low frequency bandpass filter is applied to remove signals below .66Hz and above 4Hz. As we are trying to find the peak associated with heartrate and we know the heartrate should not normally be below 40 BPM and above 240 BPM those frequencies are removed. Next we take the PPG, and all 3 accelerometer signals and create FFT to analyze in the frequency domain. From there, the method identifies the highest frequency signal in PPG, Acc_X, Acc_Y, and Acc_Z to return for evaluation. Additionally the top 4 PPG frequencies are returned along with the bandpass filtered ppg, Acc_X, Acc_Y, and Acc_Z signals.\n",
    "\n",
    "Next the algorithm attempts to identify the right frequency for the heartbeat. The initial candidate is the top PPG frequency unless it is the same as one of the accelerometer high frequencies in which case we select the second highest PPG signal. This step helps eliminate accelerometer noise in the overall signal. The second step is attempting to reduce a large swing in frequency between successive windows (which have 6 seconds of overlap). For this the last frequency is compared to the canddidate current frequency. If the new signal is greater than 10% differnce.. then we attempt to find the signal within the top 4 PPG signals that is closes to the last_frequency and use that instead. This attempts to reduce a sudden change in freqencies between windows.\n",
    "\n",
    "One a frequency is selected, it is covered into a BPM rating and compared to the reference value to determine the error. Lastly for the confidence, we take the energy within .5 Hz and consider it part of the confidence and divide it by the overall energy. The .5Hz was found through trial and error of attempting to create reliable confidence ranges.\n",
    "\n",
    "Finally the error and confidences are returned from RunPulseRateAlgorithm()\n",
    "\n",
    "##### Algorithm Performance\n",
    "Performance was computed by using the TROIKA reference data. The confidence of an estimate was determined as a percentage of the core frequency plus a small range around it relative to total signal energy. This confidence estimate was built with the presumption that the heart signal would be the strongest in the data. The performance of the algorithm attempts to remove accelerometer signal noise by not relying on the PPG top frequency if it is the same as the highest accelerometer rating. The algorithm performance is also based on assumping heartbeat patterns are stable for 8 second intervals and that there are cases where the PPG signal may be occuring faster than the heartbeat. To address these issues as noted in the algorithm description removal of the accelerometer conflicting frequency and attempting to align the frequency closer to the previous window frequency when there is a large frequency jump is done to create better performance. The other factors that play into algorithm performance are the number of top PPG signals to leverage in the case of the last frequency signficantly different than new frequency issue as well as determining when the accelerometer signal is considered the \"same\" as the PPG signal. Lastly the evaluation of the confidence metric and the range of energy to collect for the confidence is tunable as well. Leveraging all these values allowed for by-hand tuning below 15BPM on the Test (unknown) data set.\n",
    "\n",
    "Given the caveats in the Data Description section it is hard to consider this a truely generalize algorithm. It is a useful algorithm for stress test type situations where someone is evaluating from resting heart rate to a high activity rate. However as a general use algorithm night and day, the data the algorithm was designed against does not lend to that open ended use. Further data, error analysis and confidence evaluation would be required for that general algorithm. However this algorithm could be the foundation of the generalized version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
