{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import signal\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import mlab\n",
    "\n",
    "fs=125 #sampling rate\n",
    "minfreq=0.66 #40 bpm\n",
    "maxfreq=4 #240\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "    \n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "        \n",
    "    # Compute pulse rate estimates and estimation confidence.\n",
    "    errors, confidence = estimatePulseRate(ref_fl,ppg, accx, accy, accz)\n",
    "    # Return per-estimate mean absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    #errors, confidence = np.ones(100), np.ones(100)  # Dummy placeholders. Remove\n",
    "    return errors, confidence\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### My implementation ,the code in above section is skeletal code provided by udacity.\n",
    "\n",
    "Knowledge links used for reference: \n",
    "\n",
    "https://knowledge.udacity.com/questions/314330\n",
    "\n",
    "https://knowledge.udacity.com/questions/399609\n",
    "\n",
    "https://knowledge.udacity.com/questions/246546\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectogram(sig):\n",
    "    \"\"\"\n",
    "    Gets spectrogram and frequencies from given signal. \n",
    "    Calculate the magnitude of the acceleration.\n",
    "    Arguments: \n",
    "        sig: required sensor signal (e.g. ppg or acc)\n",
    "    Returns:\n",
    "        spec: ndarray\n",
    "        freqs: ndarray\n",
    "    adapted from https://knowledge.udacity.com/questions/399609\n",
    "    refered for understanding https://knowledge.udacity.com/questions/246546\n",
    "    refered to https://vibrationresearch.com/blog/what-is-a-spectrogram/\n",
    "    \"\"\"\n",
    "    spec, freqs, t=mlab.specgram(sig,NFFT=fs*8,Fs=fs,noverlap=6*fs, pad_to=10*fs)\n",
    "    spec=spec[(freqs >= minfreq) & (freqs <= maxfreq)]\n",
    "    freqs=freqs[(freqs >= minfreq) & (freqs <= maxfreq)]\n",
    "    \n",
    "    return spec, freqs\n",
    "\n",
    "def BandpassFilter(sig): \n",
    "    \"\"\"\n",
    "    BandpassFilter function  allows certain frequency range only.\n",
    "    Refer to ReadMe.md file for passband range.\n",
    "    the Readme file assumes pulse rate will be restricted between 40BPM (beats per minute) and 240BPM\n",
    "    Banpass Filter code has been adapted from Lowpassfilter in Lesson 3 \n",
    "    Returns:\n",
    "        Filtered signal\n",
    "    \"\"\"\n",
    "    pass_band=(minfreq,maxfreq) \n",
    "    b, a = scipy.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "    return scipy.signal.filtfilt(b, a, sig)\n",
    "\n",
    "def calcSNR(sig, est_freq):\n",
    "    \"\"\"\n",
    "    Calculate Signal to noise ratio to determine how clean the signal is \n",
    "    Refered to Lesson 3 Exercise 3 Solution\n",
    "    SNR was recommended to be used in https://knowledge.udacity.com/questions/399609\n",
    "    \"\"\"\n",
    "    n = len(sig)*2\n",
    "    #frequency of first harmonic\n",
    "    harmonic_f = est_freq * 2\n",
    "    \n",
    "    # do Fourier Transform\n",
    "    fft_mag = np.abs(np.fft.rfft(sig, n))\n",
    "    freqs = np.fft.rfftfreq(n, 1/fs)\n",
    "    \n",
    "    #Find the frequencies close to heart rate and first harmonic of the heart rate\n",
    "    window_f = 5/60\n",
    "    fundamental_frequency_window = (freqs > est_freq - window_f) & (freqs < est_freq + window_f)\n",
    "    harmonic_frequency_window = (freqs > harmonic_f - window_f) & (freqs < harmonic_f + window_f)\n",
    "    \n",
    "    #Calculate signal and noise power\n",
    "    sig = np.sum(fft_mag[(fundamental_frequency_window) | (harmonic_frequency_window)])\n",
    "    noise = np.sum(fft_mag[~ ((fundamental_frequency_window) | (harmonic_frequency_window))])\n",
    "    snr = sig / noise\n",
    "    \n",
    "    return snr\n",
    "\n",
    "def Featurize(ppg,accx, accy, accz,fs=fs):\n",
    "    \"\"\"Featurization of the accelerometer and ppg signal.\n",
    "        Adapted from Lesson 4 .\n",
    "      Args:\n",
    "      accx: (np.array) x-channel of the accelerometer.\n",
    "      accy: (np.array) y-channel of the accelerometer.\n",
    "      accz: (np.array) z-channel of the accelerometer.\n",
    "      fs: (number) the sampling rate of the accelerometer\n",
    "      ppg:  (np.array) ppg signal\n",
    "\n",
    "      Returns:\n",
    "       n-tuple of accelerometer and ppg features\n",
    "    \"\"\"\n",
    "    # Use Bandpass Filter to take out signals below 40 bpm and above 240 bpm\n",
    "    ppg=BandpassFilter(ppg)\n",
    "    accx=BandpassFilter(accx)\n",
    "    accy=BandpassFilter(accy)\n",
    "    accz=BandpassFilter(accz)\n",
    "    \n",
    "    #Get spectrogram frequencies\n",
    "    spec_ppg, freqs_ppg = get_spectogram(ppg)\n",
    "    spec_accx, freqs_accx = get_spectogram(accx)\n",
    "    spec_accy, freqs_accy = get_spectogram(accy)\n",
    "    spec_accz, freqs_accz = get_spectogram(accz)\n",
    "      \n",
    "    #Get frequency and time\n",
    "    freqs = freqs_ppg.shape[0]\n",
    "    t_steps = spec_ppg.shape[1]\n",
    "    \n",
    "    # Get indices for largest signal peaks\n",
    "    ppg_ind = (-spec_ppg).argsort(axis=0)\n",
    "    accx_ind = (-spec_accx).argsort(axis=0)\n",
    "    accy_ind = (-spec_accy).argsort(axis=0)\n",
    "    accz_ind = (-spec_accz).argsort(axis=0)\n",
    "    \n",
    "    return (freqs,t_steps,spec_ppg, freqs_ppg,\n",
    "            ppg_ind,accx_ind,accy_ind,accz_ind)\n",
    "           \n",
    "def estimatePulseRate(ref_f1,ppg,accx, accy, accz,fs=fs): #refer to Lesson 4\n",
    "    \"\"\"Estimates the Pulse Rate of the accelerometer and ppg signal.\n",
    "        Adapted from Lesson 4 .\n",
    "        refered for understanding https://knowledge.udacity.com/questions/246546\n",
    "      Args:\n",
    "      accx: (np.array) x-channel of the accelerometer.\n",
    "      accy: (np.array) y-channel of the accelerometer.\n",
    "      accz: (np.array) z-channel of the accelerometer.\n",
    "      fs: (number) the sampling rate of the accelerometer\n",
    "      ppg:  (np.array) ppg signal\n",
    "\n",
    "    Returns:\n",
    "        errors, confidence numpy array\n",
    "    \"\"\"\n",
    "    # get Ground Truth \n",
    "    # Load Reference\n",
    "    groundtruth = scipy.io.loadmat(ref_f1)[\"BPM0\"].reshape(-1)\n",
    "    \n",
    "    #Extract strongest frequencies in ppg and accelerometer signals \n",
    "    (freqs,t_steps,spec_ppg, freqs_ppg,\n",
    "     ppg_ind,accx_ind,accy_ind,accz_ind) = Featurize(ppg,accx, accy, accz)\n",
    "    \n",
    "    # Estimate Pulse Rates adapted from https://knowledge.udacity.com/questions/399609\n",
    "    #\n",
    "    estimated_freq=[]\n",
    "    for t in range(t_steps):\n",
    "        for freq in range(freqs):\n",
    "            i=0\n",
    "            if freq == 2:# if just peaks at 2 frequencies just pick ppg\n",
    "                estimated_freq.append(freqs_ppg[ppg_ind[freq][t]])\n",
    "                break\n",
    "            # try to remove accelerometer peaks to identify only ppg\n",
    "            # we are just doing our best to remove peaks caused due to ARM movements\n",
    "            elif np.all([(freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accx_ind[i][t]]), \n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accy_ind[i][t]]), \n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accz_ind[i][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accx_ind[i+1][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accy_ind[i+1][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accz_ind[i+1][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accx_ind[i+2][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accy_ind[i+2][t]]),\n",
    "                      (freqs_ppg[ppg_ind[freq][t]] != freqs_ppg[accz_ind[i+2][t]])]):\n",
    "                estimated_freq.append(freqs_ppg[ppg_ind[freq][t]])\n",
    "                break\n",
    "    # use SNR from Lesson 3 to determine \"purity\" of the ppg signal this is what our confidence is\n",
    "    confidence = []\n",
    "    for i in range(len(estimated_freq)):\n",
    "        snr = calcSNR(ppg, estimated_freq[i])\n",
    "       # print(\"For {}, estimated_freq={} and snr={}\".format(i, estimated_freq[i],snr))\n",
    "        confidence.append(snr)\n",
    "    \n",
    "    predicted = np.array(estimated_freq) * 60\n",
    "    \n",
    "    #Get Error and Confidence in array\n",
    "    error_arr = np.abs(groundtruth - predicted)\n",
    "    conf_arr = np.array(confidence)\n",
    "    #for i in range(len(conf_arr)):\n",
    "    #    print(\"At index {}, confidence={} and error={}\".format(i, estimated_freq[i],snr))\n",
    "    return error_arr, conf_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.877438899740184"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** - Include details so someone unfamiliar with your project will know how to run your code and use your algorithm. \n",
    "> - **Data Description** - Describe the dataset that was used to train and test the algorithm. Include its short-comings and what data would be required to build a more complete dataset.\n",
    "> - **Algorithhm Description** will include the following:\n",
    ">   - how the algorithm works\n",
    ">   - the specific aspects of the physiology that it takes advantage of\n",
    ">   - a describtion of the algorithm outputs\n",
    ">   - caveats on algorithm outputs \n",
    ">   - common failure modes\n",
    "> - **Algorithm Performance** - Detail how performance was computed (eg. using cross-validation or train-test split) and what metrics were optimized for. Include error metrics that would be relevant to users of your algorithm. Caveat your performance numbers by acknowledging how generalizable they may or may not be on different datasets.\n",
    "\n",
    "Your write-up goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code Description\n",
    "\n",
    "The first block of code is the starter code provided by UDACITY Team to load and read from the Troika dataset, a test set of data as well as reference(Ground Truth) data. \n",
    "\n",
    "Evaluate() is the final Wrapper function which outputs the aggregated error.\n",
    "\n",
    "Evaluate() calls below functions:\n",
    "1. LoadTroikaDataset() LoadTroikaDataFile(): to retrieve the data and reference filenames of the data to be processed. It then iterates across the data and reference files to extract PPG and accelerometer signals\n",
    "\n",
    "2. AggregateErrorMetric() : Returns mean absolute error based on confidense estiamtes\n",
    "\n",
    "3. RunPulseRateAlgorithm(): This is the crux of the code . IT iterates through ppg and accelerometer signals to return estiamted Pulse Rate.\n",
    "\n",
    "The second section of the code is where I made the changes. RunPulseRateAlgorithm() calls estimatePulseRate() to collect estimated pulse rate and deviation/error with regards to reference (ground truth).\n",
    "\n",
    "estimatePulseRate() calls Featurize() function to extract largest peaks at frequencies and over a time range which are basically the features for evaluation of the algorithm. \n",
    "estimatePulseRate() then iterates through all the peak frequencies to determine the second best peak by segregating acelerometer peaks.\n",
    "\n",
    "error is basically deviation between groundtruth/reference frequencies and estimated frequencies.\n",
    "Confidence is measured by how clean our signal is which can be calculated by determining Signal to Noise Ratio getSNR(). Higher the ratio cleaner the signal is.\n",
    "\n",
    "Once RunPulseRateAlgorithm() evalautes all the 8 second windows it returns error and confidence arrays to Evaluate() which then  aggregates the results and loads new file. This process is repeated until all files are processed.\n",
    "\n",
    "##### Data Description\n",
    "Please refer to Readme.pdf in data set folder for more details.\n",
    "\n",
    "The algorithm is designed to work on the Troika data set referenced above and noted here as well. The troika dataset includes two data files for each subject, the data file and a reference file. The data file contains 4 arrays of sensor data: one PPG sensor recording and 3 accelermometers (x, y, z axis). The sensors are recording at 8Hz or 125ms time frames. These are extracted in each file. The reference data file contains BPM recordings for 8 second windows recorded every 2 second. Each pair of files represents one test subject starting from rest and starting to run at 15km/hr. This shows BPM starting at resting rate and raising to a high activity rate.\n",
    "\n",
    "There is no Demographic information, such as Age,Gender,Race details which makes it difficult to be used for any application.\n",
    "\n",
    "\n",
    "Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "##### Algorithm Description\n",
    "\n",
    "The algorithm is designed to be execuited within the RunPulseRateAlgorithm() method. Within this method the data is broken down into 8 second windows for processing with the algorithm. The algorithm then uses the featurize() method to determine the important data points for evaluate.\n",
    "\n",
    "Featurize(): First a low frequency bandpass filter is applied to remove signals below .66Hz and above 4Hz. As we are trying to find the peak associated with heartrate and we know the heartrate should not normally be below 40 BPM and above 240 BPM those frequencies are removed. Next we take the PPG, and all 3 accelerometer signals and create FFT to analyze in the frequency domain. From there, the method identifies the highest frequency signal in PPG, Acc_X, Acc_Y, and Acc_Z to return for evaluation. \n",
    "\n",
    "Next the algorithm attempts to identify the right frequency for the heartbeat. If 2 stongest  peaks are identified, the second is chosen for heart rate. However if more peaks are identified, we chose the peak that does not fall under ppg and accelerometer . This step helps eliminate accelerometer noise in the overall signal.\n",
    "\n",
    "One a frequency is selected, it is converted into a BPM rating and compared to the reference value to determine the error. Lastly for the confidence, we use SNR.\n",
    "\n",
    "Finally the error and confidences are returned from RunPulseRateAlgorithm()\n",
    "\n",
    "The algorithm assumes that the second highest peak is a good estimation of Pulse Rate. However this might not always be true. When we have several signals especially accelerometer or EKG it gets harder to differentiate. Also please note that melanin on skin impacts PPG signals, so we might not get a good estiamted heart rate for a subject with darker skin tone.\n",
    "\n",
    "I believe we might need a more sophesticated process to estimate heart rate from PPG signals given the noise that comes along with this signal.\n",
    "\n",
    "##### Algorithm Performance\n",
    "Performance measure is basically determined by deviation between estimated BPM and reference BPM. The Evaluate() returned an aggregated value of 19.87. The lower this value better our Algorithm performs. Some of the ways for improving would be a better logic to isolate the accelorometer peaks from PPG. The algorithm also assumes that hearbeat is basically 2nd peak in ppg which might not always be true especially during resting period or low activity interval. PPG signals are also impacted by melanin in skin tone, higher the melanin inaccurate the PPG peaks become.\n",
    "\n",
    "\n",
    "Given the caveats in the Data Description section it is hard to consider this a truely generalize algorithm.There is no Demographic information, such as Age,Gender,Race details which makes it difficult to be used for any application.\n",
    " It is a useful algorithm during tranisiton from rest to high activity. However cannot be used as a generalized use outside the transition window.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
